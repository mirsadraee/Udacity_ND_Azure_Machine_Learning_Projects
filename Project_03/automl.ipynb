{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Automated ML\n",
        "\n",
        "Import Dependencies. In the cell below, import all the dependencies that are needed to complete the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1682177180032
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SDK version: 1.49.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import datasets\n",
        "import logging\n",
        "import json\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# !pip install kaggle\n",
        "\n",
        "# import kaggle\n",
        "\n",
        "import azureml.core\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "from azureml.core.compute import AmlCompute, ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.model import InferenceConfig, Model\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialization\n",
        "\n",
        "Initialize a workspace object from persisted configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1682177173367
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quick-starts-ws-231701\n",
            "aml-quickstarts-231701\n",
            "westeurope\n",
            "b968fb36-f06a-4c76-a15f-afab68ae7667\n",
            "An existing cluster will be used!\n",
            "Succeeded......................"
          ]
        }
      ],
      "source": [
        "ws = Workspace.from_config()\n",
        "ws = Workspace.from_config()\n",
        "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'AutoML_experiment'\n",
        "project_folder = './training'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "\n",
        "run = experiment.start_logging()\n",
        "\n",
        "# Choose a name for your CPU cluster\n",
        "cluster_name = \"compute-cluster-p3\"\n",
        "\n",
        "# Create compute cluster\n",
        "try:\n",
        "    aml_compute = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('An existing cluster will be used!')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)\n",
        "    aml_compute = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "    print('An new cluster will be created now!')\n",
        "\n",
        "aml_compute.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data\n",
        "The dataset for heart failure prediction was taken from kaggle and is saved locally. The code first tries to use that and if not reachable extract the data from the provided link.\n",
        "\n",
        "The data includes several columns, namely:\n",
        "`age`, `anaemia`, `creatinine_phosphokinase`, `diabetes`, `ejection_fraction`, `high_blood_pressure`, `platelets`, `serum_creainine`, `serum_sodium`, `sex`, `smoking`, `time` and `DEATH_EVENT`.\n",
        "\n",
        "The patients `DEATH_EVENT` will be predicted based on the the other parameters listed in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173727
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Try to load the dataset from the Workspace. Otherwise, create it from the file\n",
        "# update the key to match the dataset name\n",
        "found = False\n",
        "key = \"Experiment\"\n",
        "description_text = \"Heart Failure Prediction - Capstone Project\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "        found = True\n",
        "        dataset = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "        # Create AML Dataset and register it into Workspace\n",
        "        url = \"https://raw.githubusercontent.com/mirsadraee/Udacity_ND_Azure_Machine_Learning_Projects/develop/Project_03/heart_failure_clinical_records_dataset.csv\"\n",
        "        dataset = Dataset.Tabular.from_delimited_files(url)        \n",
        "        #Register Dataset in Workspace\n",
        "        dataset = dataset.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = dataset.to_pandas_dataframe()\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173749
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df['age'].plot.hist(bins=20, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173762
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df['smoking'].plot.hist(bins=3, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173776
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df['sex'].plot.hist(bins=3, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173790
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df['DEATH_EVENT'].plot.hist(bins=3, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173804
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "df['time'].plot.hist(bins=50, alpha=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173818
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Automl settings\n",
        "automl_settings = {\"n_cross_validations\": 2,\n",
        "                    \"primary_metric\": 'accuracy',\n",
        "                    \"enable_early_stopping\": True,\n",
        "                    \"max_concurrent_iterations\": 4,\n",
        "                    \"experiment_timeout_minutes\": 20,\n",
        "                    \"verbosity\": logging.INFO\n",
        "                    }\n",
        "\n",
        "# Parameters for AutoMLConfig\n",
        "automl_config = AutoMLConfig(compute_target = aml_compute,\n",
        "                            task='classification',\n",
        "                            training_data=dataset,\n",
        "                            label_column_name='DEATH_EVENT',\n",
        "                            path = project_folder,\n",
        "                            featurization= 'auto',\n",
        "                            debug_log = \"automl_errors.log\",\n",
        "                            enable_onnx_compatible_models=False,\n",
        "                            **automl_settings\n",
        "                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173835
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Submit the experiment\n",
        "remote_run = experiment.submit(automl_config, show_output = True)\n",
        "remote_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Details\n",
        "To use the `RunDetails` widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173849
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "RunDetails(remote_run).show()\n",
        "remote_run.wait_for_completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173863
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "best_automl_run, fitted_automl_model = remote_run.get_output()\n",
        "\n",
        "best_automl_run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173875
        }
      },
      "outputs": [],
      "source": [
        "best_automl_run.register_model(model_name = \"AutoML_best_run.pkl\", model_path = './outputs/')\n",
        "\n",
        "print(best_automl_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173889
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Save the best model\n",
        "joblib.dump(fitted_automl_model, 'outputs/AutoML_Model.joblib')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "In the cell below,  following steps are taken place:\n",
        "- register the model, \n",
        "- create an inference config and \n",
        "- deploy the model as a web service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173902
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# register the model\n",
        "model = remote_run.register_model(model_name = \"AutoML_Model\")\n",
        "\n",
        "# deploy the model\n",
        "deploy_config = AciWebservice.deploy_configuration(cpu_cores=1,memory_gb=2,enable_app_insights=True)\n",
        "\n",
        "# configure the inference\n",
        "# An inference config in Azure Machine Learning is used to define the environment and entry script required to deploy a model as a web service.\n",
        "inference_config = InferenceConfig(entry_script='./score.py')\n",
        "\n",
        "service_name = 'automl-web-service'\n",
        "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config=deploy_config)\n",
        "service.wait_for_deployment(True)\n",
        "\n",
        "print(service.state)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "In the cell below, a request is sent to the web service to test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173920
        }
      },
      "outputs": [],
      "source": [
        "scoring_uri = service.scoring_uri\n",
        "\n",
        "headers = {'Content-Type':'application/json'}\n",
        "\n",
        "test_data_1 = json.dumps({'data':[{\n",
        "    'age':75,\n",
        "    'anaemia':0,\n",
        "    'creatinine_phosphokinase':582,\n",
        "    'diabetes':0,\n",
        "    'ejection_fraction':20,\n",
        "    'high_blood_pressure':1,\n",
        "    'platelets':265000,\n",
        "    'serum_creatinine':1.9,\n",
        "    'serum_sodium':130,\n",
        "    'sex':1,\n",
        "    'smoking':0,\n",
        "    'time':4}\n",
        "    ]\n",
        "        })\n",
        "\n",
        "test_data_2 = json.dumps({'data':[{\n",
        "    'age':40,\n",
        "    'anaemia':0,\n",
        "    'creatinine_phosphokinase':321,\n",
        "    'diabetes':0,\n",
        "    'ejection_fraction':35,\n",
        "    'high_blood_pressure':0,\n",
        "    'platelets':265000,\n",
        "    'serum_creatinine':1,\n",
        "    'serum_sodium':130,\n",
        "    'sex':1,\n",
        "    'smoking':0,\n",
        "    'time':198}\n",
        "    ]\n",
        "        })\n",
        "\n",
        "response = requests.post(scoring_uri, data=test_data_1, headers=headers)\n",
        "print(\"Result 1:\",response.text)\n",
        "\n",
        "\n",
        "response = requests.post(scoring_uri, data=test_data_2, headers=headers)\n",
        "print(\"Result 2:\",response.text)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The logs of the web service are printed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173947
        }
      },
      "outputs": [],
      "source": [
        "# service.get_logs()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The service will be deleted now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1682177173960
        }
      },
      "outputs": [],
      "source": [
        "# service.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Submission Checklist**\n",
        "- [x]  I have registered the model.\n",
        "- [x]  I have deployed the model with the best accuracy as a webservice.\n",
        "- [x]  I have tested the webservice by sending a request to the model endpoint.\n",
        "- [x]  I have deleted the webservice and shutdown all the computes that I have used.\n",
        "- [x]  I have taken a screenshot showing the model endpoint as active.\n",
        "- [x]  The project includes a file containing the environment details.\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
